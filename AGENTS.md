# Repository Guidelines

This repo runs 4 DeepStream containers (s0, s1, s2, s3) for YOLOv8 inference on live RTSP streams from a MediaMTX relay.

## üö® HARDWARE CAPABILITY BASELINE

**This hardware (RTX 5080) has been tested running 168 concurrent DeepStream containers with YOLOWorld on vanilla DeepStream.**

**NEVER** claim anything is "too big", "massive", "heavy", or "resource intensive" for this hardware. If something uses high GPU/CPU, it's a **BUG or MISCONFIGURATION**, not a hardware limit.

**Models tested at scale:**
- YOLOWorld (largest YOLO variant) - 168 concurrent streams ‚úì
- YOLO12x (226MB ONNX) - Proven working at scale
- YOLOv8n (13MB ONNX) - Lightweight baseline

**Expected performance per stream (FP16 TensorRT + NVDEC decode + batching):**
- CPU: <10% per container (GPU-bound workload)
- GPU: 30-50% for YOLO12x @1280 (single stream with FP16)
- GPU: 45-75% only if FP32/CPU decode (misconfiguration)
- Any single stream using >90% GPU = BUG (wrong precision mode, CPU decode, no batching, or corrupted engine cache)

**Debug checklist for high GPU usage:**
1. Check `network-mode=2` (FP16) in config, not FP32
2. Verify `cudadec-memtype=0` (NVDEC GPU decode)
3. Confirm TensorRT `.engine` file exists and is valid
4. Enable batching: `batch-size=4` and `process-mode=1`
5. Check for NVENC/display overhead (`nvdsosd` + `nveglglessink`)
6. Delete and rebuild `.engine` files if switching models

## ‚ö†Ô∏è IMPORTANT: Always Use Managed Scripts

**DO NOT use raw docker/mediamtx/frp commands**. This repo provides managed lifecycle scripts that handle system state correctly.

**ALWAYS use these managed scripts**:
- `./system` - Full system management (frpc + DeepStream)
- `./ds` - DeepStream containers only
- `./relay` - Remote relay management
- `./.scripts/debug.sh` - Debugging diagnostics
- `./.scripts/check.sh` - Health validation

**Only use raw commands if explicitly documented** in these scripts or if the managed scripts don't provide what you need.

## Component Navigation

### Three Main Components

**1. DeepStream Containers** (Core System)
- **Location**: Managed by `./ds` and `./system` scripts
- **What**: Four containers (ds-s0, ds-s1, ds-s2, ds-s3) running YOLOv8 inference
- **Start**: `./system start` or `./ds start`
- **Stop**: `./system stop` or `./ds stop`
- **Status**: `./ds status`
- **Debug**: `./.scripts/debug.sh`

**2. FRP Tunnel + Relay** (Connectivity)
- **Local (frpc)**: Managed by `./system` script, config in `.scripts/frpc/frpc.ini`
- **Remote (relay)**: Managed by `./relay` script, runs on GCP VM
- **What**: Tunnels local RTSP to public relay for WebRTC streaming
- **Start**: `./system start` (starts frpc)
- **Check**: `./system status` or `./relay status`

## Architecture

### Current Setup (4 Live Streams)
- **ds-s0**: Pulls from `rtsp://RELAY_IP:8554/in_s0`, serves on `localhost:8554/ds-test`
- **ds-s1**: Pulls from `rtsp://RELAY_IP:8554/in_s1`, serves on `localhost:8555/ds-test`
- **ds-s2**: Pulls from `rtsp://RELAY_IP:8554/in_s2`, serves on `localhost:8556/ds-test`
- **ds-s3**: Pulls from `rtsp://RELAY_IP:8554/in_s3`, serves on `localhost:8557/ds-test`

All 4 use **single parameterized C binary** (`live_stream`) that takes stream ID (0, 1, 2, 3) and orientation as arguments.

### Data Flow
```
Cameras ‚Üí Relay (in_s0, in_s1, in_s2, in_s3)
         ‚Üì
DeepStream pulls from relay ‚Üí YOLOv8 inference ‚Üí Local RTSP (8554, 8555, 8556, 8557)
         ‚Üì
frpc tunnels localhost ‚Üí Relay (9500, 9501, 9502, 9503)
         ‚Üì
Relay pulls from tunnels ‚Üí Serves as s0, s1, s2, s3 (WebRTC/HLS/RTSP)
```

### Key Components

**MediaMTX Relay** (managed by Terraform in `relay_infra/`):
- **Current IP**: `34.47.221.242`
- **Inputs**: `in_s0`, `in_s1`, `in_s2`, `in_s3` (cameras publish here)
- **Outputs**: `s0`, `s1`, `s2`, `s3` (pulls from localhost:9500-9503 via frp tunnels)
- **Config**: `/etc/mediamtx/config.yml` (generated by `relay_infra/scripts/startup.sh`)
- **Manage**: Use `./relay status` or `./relay restart` (DO NOT ssh manually)

**frp Tunneling**:
- **frps** (server): Runs on relay, accepts tunnels on port 7000
- **frpc** (client): Runs locally, tunnels localhost:8554-8557 ‚Üí relay:9500-9503
- **Config**: `.scripts/frpc/frpc.ini` (contains relay IP and token)
- **Manage**: Use `./system start/stop/restart` (DO NOT run frpc manually)

**DeepStream Containers**:
- All use YOLOv8n COCO by default (`config/config_infer_yolov8.txt`)
- All use portrait mode (720x1280) by default
- All use batch-size=1 for single-stream inference
- All built from same Docker image with single parameterized binary
- Launched with different stream IDs: `/app/live_stream 0 portrait`, `/app/live_stream 1 portrait`, etc.

## Critical Files Containing Relay IP

When the relay IP changes, update ALL of these:
1. `live_stream.c` (line 96: `snprintf(input_uri, ...)`)
2. `.scripts/frpc/frpc.ini` (line 2: `server_addr`, line 4: `token`)

**Much simpler now**: Only 2 files instead of 6 thanks to parameterized binary.

## Relay Changes (Terraform Workflow)

The relay is **infrastructure as code**. Changes to `relay/scripts/startup.sh` require recreating the VM.

### To Update Relay Config
```bash
cd relay/

# 1. Make changes to relay/scripts/startup.sh
# 2. Destroy and recreate (IP will change unless you have static IP)
export GOOGLE_OAUTH_ACCESS_TOKEN=$(gcloud auth print-access-token)
terraform destroy -var project_id=fsp-api-1 -auto-approve
terraform apply -var project_id=fsp-api-1 -auto-approve

# 3. Note the new external_ip from output
terraform output external_ip

# 4. Get the new frps_token
terraform output -raw frps_token
```

### After Relay IP Change
```bash
# 1. Update all 3 files listed above with new IP and token
# 2. Rebuild Docker images
./build.sh

# 3. Restart entire system (frpc + containers)
./system restart

# 4. Verify everything started
./system status
```

## frpc (Local FRP Client)

**What it does**: Tunnels DeepStream's local RTSP servers to the relay so viewers can access processed streams.

**When to restart**:
- After changing `.scripts/frpc/frpc.ini` (IP or token change)
- If relay was recreated
- If tunnels disconnect (check logs)

**How to restart**:
```bash
./system restart    # Preferred: Restarts frpc + containers together
```

**How to check status**:
```bash
./system status     # Full health check
# Or manually check logs:
tail -20 /var/log/frpc.log
# Good: "login to server success", "proxy added: [s0_rtsp s1_rtsp s2_rtsp]"
# Bad: "dial tcp ... i/o timeout" (wrong IP), "authorization failed" (wrong token)
```

## Quick Workflow

### Start Everything
```bash
./build.sh         # Rebuild if live_stream.c changed
./system start     # Start frpc + all DeepStream containers
```

### Stop Everything
```bash
./system stop      # Stop all containers + frpc
```

### Check Status
```bash
./system status        # Full health check (frpc, DS, relay) - USE THIS FIRST
./ds status            # Just container status
./relay status         # Just relay status
./.scripts/debug.sh    # Detailed diagnostics
```

### Debug Issues
```bash
./.scripts/debug.sh    # ALWAYS run this first for debugging
# Only check individual logs if debug script tells you to
```

### View processed streams
- s0: `http://34.47.221.242:8889/s0/`
- s1: `http://34.47.221.242:8889/s1/`
- s2: `http://34.47.221.242:8889/s2/`
- s3: `http://34.47.221.242:8889/s3/`

### View input streams (before processing)
- in_s0: `http://34.47.221.242:8889/in_s0/`
- in_s1: `http://34.47.221.242:8889/in_s1/`
- in_s2: `http://34.47.221.242:8889/in_s2/`
- in_s3: `http://34.47.221.242:8889/in_s3/`

## Swapping Models

To change from YOLOv8n to another model:
```bash
# 1. Create new config pointing to new ONNX
cp config/config_infer_yolov8.txt config/config_infer_new.txt
vim config/config_infer_new.txt
# Update: onnx-file=/models/new_model.onnx
# Update: model-engine-file=/models/new_model_b1_gpu0_fp16.engine

# 2. Edit inference config path in live_stream.c
sed -i 's|config_infer_yolov8.txt|config_infer_new.txt|' live_stream.c

# 3. Rebuild and restart
./build.sh
./ds restart

# DeepStream will auto-build the new engine (no need to delete old ones)
```

## TensorRT Engine Management

### How Engine Caching Actually Works (CRITICAL UNDERSTANDING)

**DeepStream saves engines to `/app/`, NOT `/models/`**:
- Config specifies: `model-engine-file=/models/xxx.engine` (where it LOADS from)
- DeepStream saves to: `/app/model_b1_gpu0_fp16.engine` (hardcoded in DeepStream-YOLO)
- `/app/` is NOT bind-mounted ‚Üí engines lost on container restart
- `/models/` IS bind-mounted ‚Üí engines persist across restarts

**The Problem**: First run builds engine to `/app/`, second run can't find it in `/models/`, rebuilds again.

**The Solution**: Use `.scripts/cache_engine.sh` to copy engines from `/app/` ‚Üí `/models/` with correct names.

### Engine Cache Management Script

Use `.scripts/cache_engine.sh` for all engine operations:

```bash
# After first container start (engines built in /app/)
./.scripts/cache_engine.sh copy     # Copy engines to /models/ with correct names

# Check engine locations
./.scripts/cache_engine.sh list     # Show engines in containers + /models/

# Verify configs point to existing cached engines
./.scripts/cache_engine.sh verify   # Check config ‚Üí engine mappings

# Force clean rebuild (rarely needed)
./.scripts/cache_engine.sh clean    # Delete cached engines from /models/
./ds restart                        # Containers rebuild in /app/
./.scripts/cache_engine.sh copy     # Copy to /models/ again
```

### Typical Workflow: Adding New Model

```bash
# 1. Train and export ONNX (in training/)
cp training/path/to/best.onnx models/new_model.onnx

# 2. Create/update config
vim config/config_infer_new.txt
# onnx-file=/models/new_model.onnx
# model-engine-file=/models/new_model_b1_gpu0_fp16.engine

# 3. Update container config in ds script or live_stream.c
# 4. Start containers (engines build in /app/)
./ds restart

# 5. Wait for "Pipeline set to PLAYING" (3-10 min depending on model)
docker logs ds-s2 | grep "PLAYING"

# 6. Copy engines to cache
./.scripts/cache_engine.sh copy

# 7. Verify configs point to cached engines
./.scripts/cache_engine.sh verify

# 8. Restart to verify cache reuse (should be instant)
./ds restart
docker logs ds-s2 | grep "deserialized trt engine"
# Should see: "deserialized trt engine from :/models/new_model_b1_gpu0_fp16.engine"
```

### How Caching Works After Setup

```
First Run (no cache):
1. DeepStream checks /models/xxx.engine ‚Üí not found
2. Builds engine from ONNX (3-10 minutes)
3. Saves to /app/model_b1_gpu0_fp16.engine
4. Runs inference

Manual step:
5. ./.scripts/cache_engine.sh copy ‚Üí copies /app/ ‚Üí /models/ with correct name

Second Run (with cache):
1. DeepStream checks /models/xxx.engine ‚Üí found!
2. Deserializes from cache (instant)
3. Runs inference

Without manual copy, step 1 fails every restart ‚Üí rebuild loop
```

### When to Use cache_engine.sh

**ALWAYS run after**:
1. First deployment of new model
2. Rebuilding engines (after ONNX change)
3. Moving to different GPU architecture

**Check cache status**:
```bash
./.scripts/cache_engine.sh list
```

**Expected output after successful cache**:
```
=== Engines in /models/ (bind-mounted, persistent) ===
-rw-r--r-- 1 root root 56M Oct 23 14:03 bowling_roboflow_1280_b1_gpu0_fp16.engine
-rw-r--r-- 1 root root 11M Oct 23 14:05 yolov8n_b1_gpu0_fp16.engine
```

### Only Delete Engines If
1. **Testing fresh build** - want to time build process
2. **Debugging engine corruption** - engine crashes on deserialize
3. **Disk cleanup** - removing old unused engines

```bash
# Delete specific engine
./.scripts/cache_engine.sh clean    # Or manually:
rm /root/d_final/models/old_model_b1_gpu0_fp16.engine
```

## Performance

All 4 streams process at ~30 FPS with YOLOv8n in portrait mode (720x1280). Check with:
```bash
./.scripts/debug.sh    # Shows GPU usage and container status
```

GPU memory usage per container: ~390 MiB

## Recent Changes

### Major Cleanup (2025-10-20)
1. **DRY principle**: Replaced 3 duplicate C files with single parameterized `live_stream.c`
2. **Script consolidation**: Simplified 11 scripts down to 4 (`system`, `ds`, `relay`, `build.sh`)
3. **Utilities hidden**: Moved check.sh, debug.sh, frpc config to `.scripts/`
4. **Publisher removed**: All publisher code removed from codebase (use external publisher for testing)

### Benefits
- **Simpler IP updates**: 2 files instead of 6
- **Easier management**: `./system start` for everything, `./ds start` for containers only
- **Clean separation**: Core system only, test tools external

### Component Separation
- **Production system**: `/root/d_final/` - frpc + DeepStream (s0, s1, s2, s3) - managed by `./system`
- **Training system**: `/root/d_final/training/` - model training and ONNX export
- **Relay**: Remote infrastructure - managed by `./relay`

### Migration Notes
If you have old code referencing:
- `live_s0/s1/s2` binaries ‚Üí Use `/app/live_stream 0/1/2` instead
- `start.sh/stop.sh` ‚Üí Use `./system start/stop` or `./ds start/stop`
- `frpc/frpc.ini` ‚Üí Now `.scripts/frpc/frpc.ini`
- `check.sh/debug.sh` ‚Üí Now `.scripts/check.sh` and `.scripts/debug.sh`

## Expectations for AI Agents

1. **ALWAYS use managed scripts**: `./system`, `./ds`, `./relay`, `./.scripts/debug.sh` - NOT raw docker/frp/mediamtx commands
2. **Check status before debugging**: Run `./system status` and `./.scripts/debug.sh` before investigating issues
3. **Relay is immutable**: Changes to `relay_infra/scripts/startup.sh` require terraform destroy/apply
4. **frpc is critical**: Without it, relay can't pull processed streams - manage via `./system`
5. **All 4 streams identical**: Same binary, same config, just different stream ID (0-3) and orientation
6. **Don't modify working streams**: If s0-s2 work but s3 doesn't, leave s0-s2 alone
7. **NEVER delete TensorRT engines**: Engines are cached in `/models/` (bind-mounted from host) and persist across restarts - DeepStream auto-rebuilds when needed
8. **Training separation**: Production code in `/root/d_final/`, training experiments in `/root/d_final/training/`

## Training Workflow

### Separation of Concerns
- **Production**: `/root/d_final/` - deployed code, managed via `./system`, `./ds`, `./relay`
- **Training**: `/root/d_final/training/` - model training, ONNX export, experiments
- **Models**: `/root/d_final/models/` - production ONNX files only

### Training Directory Structure
```
training/
‚îú‚îÄ‚îÄ train_bowling.py              # Training script
‚îú‚îÄ‚îÄ Bowling-Pin-Detection--4/     # Roboflow dataset (868 images, 1 class)
‚îÇ   ‚îú‚îÄ‚îÄ train/images/
‚îÇ   ‚îú‚îÄ‚îÄ valid/images/
‚îÇ   ‚îî‚îÄ‚îÄ data.yaml
‚îî‚îÄ‚îÄ roboflow_bowling/             # Training runs
    ‚îú‚îÄ‚îÄ bowling_1280_m_b8/        # YOLOv8m, batch=8, 1280x1280
    ‚îÇ   ‚îî‚îÄ‚îÄ weights/
    ‚îÇ       ‚îú‚îÄ‚îÄ best.pt           # 92.7% precision, 88.9% recall
    ‚îÇ       ‚îî‚îÄ‚îÄ best.onnx         # Exported ONNX
    ‚îî‚îÄ‚îÄ ...other experiments
```

### Adding New Models
```bash
# 1. Train in /root/d_final/training/
cd /root/d_final/training
python3 train_bowling.py --imgsz 1280 --batch 8 --epochs 150

# 2. Export ONNX with FIXED dimensions (dynamic=False)
docker run --rm --gpus all -v /root/d_final/training:/data \
  ultralytics/ultralytics:latest yolo export \
  model=/data/roboflow_bowling/bowling_1280_m_b8/weights/best.pt \
  format=onnx imgsz=1280 dynamic=False simplify=True

# 3. Copy to production models/
cp training/roboflow_bowling/bowling_1280_m_b8/weights/best.onnx \
   models/bowling_roboflow_1280.onnx

# 4. Create or update config
cp config/config_infer_yolov8.txt config/config_infer_bowling.txt
vim config/config_infer_bowling.txt
# Update: onnx-file=/models/bowling_roboflow_1280.onnx
# Update: model-engine-file=/models/bowling_roboflow_1280_b1_gpu0_fp16.engine
# Update: num-detected-classes=1
# Update: labelfile-path=/models/bowling_labels.txt

# 5. Restart container - engine builds automatically
./ds restart

# NO need to delete engines - DeepStream auto-rebuilds when missing
```

### Current Models
- **s0, s1**: YOLOv8n COCO (80 classes) - 720x1280 portrait
- **s2**: YOLOv8n COCO (80 classes) - 720x1280 portrait
- **s3**: YOLOv8m Bowling Roboflow (1 class) - 720x1280 portrait, 92.7% precision

### Training Lessons Learned
- **Use dynamic=False**: DeepStream requires fixed input dimensions, not variable
- **Batch size matters**: batch=8 works with concurrent DeepStream; batch=16 needs more GPU memory
- **Early stopping works**: YOLOv8m reached 92.7% precision at epoch 70 with patience=20
- **Roboflow datasets**: Company datasets often better than auto-labeled custom data
- **Export format**: Use DeepStream-Yolo export scripts with Ultralytics base image for proper output layer format
  - Script: `training/scripts/export_deepstream.sh`
  - Uses DeepStream-Yolo's export_yoloV8.py with DeepStreamOutput layer
  - Ensures compatibility with custom parser (libnvdsinfer_custom_impl_Yolo.so)
