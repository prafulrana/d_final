# Repository Guidelines

This repo runs 3 DeepStream containers (s0, s1, s2) for YOLOv8 inference on live RTSP streams from a MediaMTX relay.

## Component Navigation

### Three Main Components

**1. DeepStream Containers** (Core System)
- **Location**: Managed by `./ds` and `./system` scripts
- **What**: Three containers (ds-s0, ds-s1, ds-s2) running YOLOv8 inference
- **Start**: `./system start` or `./ds start`
- **Stop**: `./system stop` or `./ds stop`
- **Status**: `./ds status`

**2. FRP Tunnel + Relay** (Connectivity)
- **Local (frpc)**: Managed by `./system` script, config in `.scripts/frpc/frpc.ini`
- **Remote (relay)**: Managed by `./relay` script, runs on GCP VM
- **What**: Tunnels local RTSP to public relay for WebRTC streaming
- **Start**: `./system start` (starts frpc)
- **Check**: `./system status` or `./relay status`

## Architecture

### Current Setup (3 Live Streams)
- **ds-s0**: Pulls from `rtsp://RELAY_IP:8554/in_s0`, serves on `localhost:8554/ds-test`
- **ds-s1**: Pulls from `rtsp://RELAY_IP:8554/in_s1`, serves on `localhost:8555/ds-test`
- **ds-s2**: Pulls from `rtsp://RELAY_IP:8554/in_s2`, serves on `localhost:8556/ds-test`

All 3 use **single parameterized C binary** (`live_stream`) that takes stream ID (0, 1, 2) as argument.

### Data Flow
```
Cameras → Relay (in_s0, in_s1, in_s2)
         ↓
DeepStream pulls from relay → YOLOv8 inference → Local RTSP (8554, 8555, 8556)
         ↓
frpc tunnels localhost → Relay (9500, 9501, 9502)
         ↓
Relay pulls from tunnels → Serves as s0, s1, s2 (WebRTC/HLS/RTSP)
```

### Key Components

**MediaMTX Relay** (managed by Terraform in `relay/`):
- **Current IP**: `34.47.221.242`
- **Inputs**: `in_s0`, `in_s1`, `in_s2` (cameras publish here)
- **Outputs**: `s0`, `s1`, `s2` (pulls from localhost:9500-9502 via frp tunnels)
- **Config**: `/etc/mediamtx/config.yml` (generated by `relay/scripts/startup.sh`)

**frp Tunneling**:
- **frps** (server): Runs on relay, accepts tunnels on port 7000
- **frpc** (client): Runs locally, tunnels localhost:8554-8556 → relay:9500-9502
- **Config**: `frpc/frpc.ini` (contains relay IP and token)

**DeepStream Containers**:
- All use YOLOv8n (`config/config_infer_yolov8.txt`)
- All use batch-size=1 for single-stream inference
- All built from same Docker image with single parameterized binary
- Launched with different stream IDs: `/app/live_stream 0`, `/app/live_stream 1`, `/app/live_stream 2`

## Critical Files Containing Relay IP

When the relay IP changes, update ALL of these:
1. `live_stream.c` (line 96: `snprintf(input_uri, ...)`)
2. `.scripts/frpc/frpc.ini` (line 2: `server_addr`, line 4: `token`)

**Much simpler now**: Only 2 files instead of 6 thanks to parameterized binary.

## Relay Changes (Terraform Workflow)

The relay is **infrastructure as code**. Changes to `relay/scripts/startup.sh` require recreating the VM.

### To Update Relay Config
```bash
cd relay/

# 1. Make changes to relay/scripts/startup.sh
# 2. Destroy and recreate (IP will change unless you have static IP)
export GOOGLE_OAUTH_ACCESS_TOKEN=$(gcloud auth print-access-token)
terraform destroy -var project_id=fsp-api-1 -auto-approve
terraform apply -var project_id=fsp-api-1 -auto-approve

# 3. Note the new external_ip from output
terraform output external_ip

# 4. Get the new frps_token
terraform output -raw frps_token
```

### After Relay IP Change
```bash
# 1. Update all 3 files listed above with new IP and token
# 2. Rebuild Docker images
./build.sh

# 3. Restart entire system (frpc + containers)
./system restart

# 4. Verify everything started
./system status
```

## frpc (Local FRP Client)

**What it does**: Tunnels DeepStream's local RTSP servers to the relay so viewers can access processed streams.

**When to restart**:
- After changing `.scripts/frpc/frpc.ini` (IP or token change)
- If relay was recreated
- If tunnels disconnect (check logs)

**How to restart**:
```bash
./system restart    # Preferred: Restarts frpc + containers together
```

**How to check status**:
```bash
./system status     # Full health check
# Or manually check logs:
tail -20 /var/log/frpc.log
# Good: "login to server success", "proxy added: [s0_rtsp s1_rtsp s2_rtsp]"
# Bad: "dial tcp ... i/o timeout" (wrong IP), "authorization failed" (wrong token)
```

## Quick Workflow

### Start Everything
```bash
./build.sh         # Rebuild if live_stream.c changed
./system start     # Start frpc + all DeepStream containers
```

### Stop Everything
```bash
./system stop      # Stop all containers + frpc
```

### Check Status
```bash
./system status    # Full health check (frpc, DS, relay)
./ds status        # Just container status
./relay status     # Just relay status
```

### Debug DeepStream Containers
```bash
docker logs ds-s0 --tail 20   # Check s0 logs
docker logs ds-s1 --tail 20   # Check s1 logs
docker logs ds-s2 --tail 20   # Check s2 logs

# Or use debug script
./.scripts/debug.sh
```

### View processed streams
- s0: `http://34.47.221.242:8889/s0/`
- s1: `http://34.47.221.242:8889/s1/`
- s2: `http://34.47.221.242:8889/s2/`

### View input streams (before processing)
- in_s0: `http://34.47.221.242:8889/in_s0/`
- in_s1: `http://34.47.221.242:8889/in_s1/`
- in_s2: `http://34.47.221.242:8889/in_s2/`

## Swapping Models

To change from YOLOv8n to another model:
```bash
# Edit inference config path in live_stream.c
sed -i 's|config_infer_yolov8.txt|config_infer_new.txt|' live_stream.c

# Rebuild
./build.sh

# Clear old engines
rm models/*.engine

# Restart
./start.sh
```

## TensorRT Engine Management

### First Build (No Cached Engine)
**IMPORTANT**: Avoid race conditions when building engines for the first time:
```bash
# Stop all containers
docker stop ds-s0 ds-s1 ds-s2

# Start ONLY s0 to build engine
docker start ds-s0

# Wait ~3-5 minutes for engine build
# Watch logs: docker logs ds-s0 -f

# Once complete, restart all containers
./start.sh
```

### Rebuilding Engines
When dimensions or model changes:
```bash
rm models/*.engine    # Clear cached engines
./start.sh            # All containers use shared engine file
```

## Performance

All 3 streams process at ~30 FPS with YOLOv8n. Check with:
```bash
docker logs ds-s0 | grep "**PERF"
docker logs ds-s1 | grep "**PERF"
docker logs ds-s2 | grep "**PERF"
```

GPU memory usage per container: ~390 MiB
```bash
nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv
```

## Recent Changes

### Major Cleanup (2025-10-20)
1. **DRY principle**: Replaced 3 duplicate C files with single parameterized `live_stream.c`
2. **Script consolidation**: Simplified 11 scripts down to 4 (`system`, `ds`, `relay`, `build.sh`)
3. **Utilities hidden**: Moved check.sh, debug.sh, frpc config to `.scripts/`
4. **Publisher removed**: All publisher code removed from codebase (use external publisher for testing)

### Benefits
- **Simpler IP updates**: 2 files instead of 6
- **Easier management**: `./system start` for everything, `./ds start` for containers only
- **Clean separation**: Core system only, test tools external

### Component Separation
- **Core system**: frpc + DeepStream (s0, s1, s2) - managed by `./system`
- **Relay**: Remote infrastructure - managed by `./relay`

### Migration Notes
If you have old code referencing:
- `live_s0/s1/s2` binaries → Use `/app/live_stream 0/1/2` instead
- `start.sh/stop.sh` → Use `./system start/stop` or `./ds start/stop`
- `frpc/frpc.ini` → Now `.scripts/frpc/frpc.ini`
- `check.sh/debug.sh` → Now `.scripts/check.sh` and `.scripts/debug.sh`

## Expectations for Future Edits

1. **IP changes less disruptive**: Only 3 files to update (was 6)
2. **Relay is immutable**: Changes to `relay/scripts/startup.sh` require terraform destroy/apply
3. **frpc is critical**: Without it, relay can't pull processed streams
4. **All 3 streams identical**: Same binary, same config, just different stream ID
5. **Don't modify s0/s1 when debugging s2**: They work, leave them alone
6. **TensorRT engine caching**: Build once, share across all containers (but watch for race conditions on first build)

## Portrait Video Implementation Checklist

Before starting portrait video work, ensure baseline is stable by running:
```bash
./system.sh status    # All checks should pass
git status            # Should be clean
```

### Phase 1: Research & Planning
- [ ] Study NVIDIA DeepStream portrait video handling
- [ ] Test current setup with portrait input
- [ ] Document observed issues (aspect ratio, bounding boxes, etc.)
- [ ] Identify required nvstreammux/nvosd/encoder changes

### Phase 2: Configuration Changes
- [ ] Update nvstreammux dimensions in live_stream.c (currently 1920x1080)
- [ ] Test with maintain-aspect-ratio=0 vs maintain-aspect-ratio=1
- [ ] Adjust OSD properties for portrait coordinates
- [ ] Update encoder settings if needed (iframeinterval, bitrate)
- [ ] Test TensorRT engine rebuild with new dimensions

### Phase 3: Testing & Validation
- [ ] Verify FPS remains ~30 with portrait video
- [ ] Check bounding box coordinates are correct
- [ ] Verify GPU memory usage is acceptable
- [ ] Test all 3 streams with portrait input
- [ ] Check WebRTC playback on relay

### Phase 4: Rollback Plan
If portrait implementation fails:
```bash
git reset --hard pre-portrait-stable  # Reset to stable tag
./build.sh                             # Rebuild
./system.sh restart                    # Restart
```

### Key Risks
1. **Aspect ratio handling**: maintain-aspect-ratio=1 adds padding, =0 may distort
2. **TensorRT engine size**: Portrait may require different input dimensions
3. **Coordinate mapping**: YOLOv8 bbox coords may need adjustment for portrait
4. **Performance**: Different resolution may impact FPS

### Success Criteria
- [ ] All 3 streams process portrait video at 30 FPS
- [ ] Bounding boxes correctly positioned on people
- [ ] No GPU memory issues
- [ ] WebRTC playback works on relay
- [ ] System remains stable after 10 minutes of operation
