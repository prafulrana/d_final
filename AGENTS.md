# Repository Guidelines

This repo runs 4 DeepStream containers (s0, s1, s2, s3) for YOLOv8 inference on live RTSP streams from a MediaMTX relay.

## üö® HARDWARE CAPABILITY BASELINE

**This hardware (RTX 5080) has been tested running 168 concurrent DeepStream containers with YOLOWorld on vanilla DeepStream.**

**NEVER** claim anything is "too big", "massive", "heavy", or "resource intensive" for this hardware. If something uses high GPU/CPU, it's a **BUG or MISCONFIGURATION**, not a hardware limit.

**Models tested at scale:**
- YOLOWorld (largest YOLO variant) - 168 concurrent streams ‚úì
- YOLO12x (226MB ONNX) - Proven working at scale
- YOLOv8n (13MB ONNX) - Lightweight baseline

**Expected performance per stream (FP16 TensorRT + NVDEC decode + batching):**
- CPU: <10% per container (GPU-bound workload)
- GPU: 30-50% for YOLO12x @1280 (single stream with FP16)
- GPU: 45-75% only if FP32/CPU decode (misconfiguration)
- Any single stream using >90% GPU = BUG (wrong precision mode, CPU decode, no batching, or corrupted engine cache)

**Debug checklist for high GPU usage:**
1. Check `network-mode=2` (FP16) in config, not FP32
2. Verify `cudadec-memtype=0` (NVDEC GPU decode)
3. Confirm TensorRT `.engine` file exists and is valid
4. Enable batching: `batch-size=4` and `process-mode=1`
5. Check for NVENC/display overhead (`nvdsosd` + `nveglglessink`)
6. Delete and rebuild `.engine` files if switching models

## ‚ö†Ô∏è IMPORTANT: Always Use Managed Scripts

**DO NOT use raw docker/mediamtx/frp commands**. This repo provides managed lifecycle scripts that handle system state correctly.

**ALWAYS use these managed scripts**:
- `infra/system` - Full system management (frpc + DeepStream)
- `./ds` - DeepStream containers only
- `infra/relay` - Remote relay management
- `infra/scripts/debug.sh` - Debugging diagnostics
- `infra/scripts/check.sh` - Health validation

**Only use raw commands if explicitly documented** in these scripts or if the managed scripts don't provide what you need.

## Component Navigation

### Three Main Components

**1. DeepStream Containers** (Core System)
- **Location**: Managed by `./ds` and `infra/system` scripts
- **What**: Four containers (ds-s0, ds-s1, ds-s2, ds-s3) running YOLOv8 inference
- **Start**: `infra/system start` or `./ds start`
- **Stop**: `infra/system stop` or `./ds stop`
- **Status**: `./ds status`
- **Debug**: `infra/scripts/debug.sh`

**2. FRP Tunnel + Relay** (Connectivity)
- **Local (frpc)**: Managed by `infra/system` script, config in `infra/scripts/frpc/frpc.ini`
- **Remote (relay)**: Managed by `infra/relay` script, runs on GCP VM
- **What**: Tunnels local RTSP to public relay for WebRTC streaming
- **Start**: `infra/system start` (starts frpc)
- **Check**: `infra/system status` or `infra/relay status`

## Architecture

### Current Setup (4 Live Streams)
- **ds-s0**: Pulls from `rtsp://RELAY_IP:8554/in_s0`, serves on `localhost:8554/ds-test`
- **ds-s1**: Pulls from `rtsp://RELAY_IP:8554/in_s1`, serves on `localhost:8555/ds-test`
- **ds-s2**: Pulls from `rtsp://RELAY_IP:8554/in_s2`, serves on `localhost:8556/ds-test`
- **ds-s3**: Pulls from `rtsp://RELAY_IP:8554/in_s3`, serves on `localhost:8557/ds-test`

All 4 use **single parameterized C binary** (`live_stream`) that takes stream ID (0, 1, 2, 3) and orientation as arguments.

### Data Flow
```
Cameras ‚Üí Relay (in_s0, in_s1, in_s2, in_s3)
         ‚Üì
DeepStream pulls from relay ‚Üí YOLOv8 inference ‚Üí Local RTSP (8554, 8555, 8556, 8557)
         ‚Üì
frpc tunnels localhost ‚Üí Relay (9500, 9501, 9502, 9503)
         ‚Üì
Relay pulls from tunnels ‚Üí Serves as s0, s1, s2, s3 (WebRTC/HLS/RTSP)
```

### Key Components

**MediaMTX Relay** (managed by Terraform in `relay_infra/`):
- **Current IP**: `34.47.221.242`
- **Inputs**: `in_s0`, `in_s1`, `in_s2`, `in_s3` (cameras publish here)
- **Outputs**: `s0`, `s1`, `s2`, `s3` (pulls from localhost:9500-9503 via frp tunnels)
- **Config**: `/etc/mediamtx/config.yml` (generated by `relay_infra/scripts/startup.sh`)
- **Manage**: Use `infra/relay status` or `infra/relay restart` (DO NOT ssh manually)

**frp Tunneling**:
- **frps** (server): Runs on relay, accepts tunnels on port 7000
- **frpc** (client): Runs locally, tunnels localhost:8554-8557 ‚Üí relay:9500-9503
- **Config**: `infra/scripts/frpc/frpc.ini` (contains relay IP and token)
- **Manage**: Use `infra/system start/stop/restart` (DO NOT run frpc manually)

**DeepStream Containers**:
- All use YOLOv8n COCO by default (`config/config_infer_yolov8.txt`)
- All use portrait mode (720x1280) by default
- All use batch-size=1 for single-stream inference
- All built from same Docker image with single parameterized binary
- Launched with different stream IDs: `/app/live_stream 0 portrait`, `/app/live_stream 1 portrait`, etc.

## Critical Files Containing Relay IP

When the relay IP changes, update ALL of these:
1. `live_stream.c` (line 96: `snprintf(input_uri, ...)`)
2. `infra/scripts/frpc/frpc.ini` (line 2: `server_addr`, line 4: `token`)

**Much simpler now**: Only 2 files instead of 6 thanks to parameterized binary.

## Relay Changes (Terraform Workflow)

The relay is **infrastructure as code**. Changes to `relay/scripts/startup.sh` require recreating the VM.

### To Update Relay Config
```bash
cd relay/

# 1. Make changes to relay/scripts/startup.sh
# 2. Destroy and recreate (IP will change unless you have static IP)
export GOOGLE_OAUTH_ACCESS_TOKEN=$(gcloud auth print-access-token)
terraform destroy -var project_id=fsp-api-1 -auto-approve
terraform apply -var project_id=fsp-api-1 -auto-approve

# 3. Note the new external_ip from output
terraform output external_ip

# 4. Get the new frps_token
terraform output -raw frps_token
```

### After Relay IP Change
```bash
# 1. Update all 3 files listed above with new IP and token
# 2. Rebuild Docker images
./build.sh

# 3. Restart entire system (frpc + containers)
infra/system restart

# 4. Verify everything started
infra/system status
```

## frpc (Local FRP Client)

**What it does**: Tunnels DeepStream's local RTSP servers to the relay so viewers can access processed streams.

**When to restart**:
- After changing `infra/scripts/frpc/frpc.ini` (IP or token change)
- If relay was recreated
- If tunnels disconnect (check logs)

**How to restart**:
```bash
infra/system restart    # Preferred: Restarts frpc + containers together
```

**How to check status**:
```bash
infra/system status     # Full health check
# Or manually check logs:
tail -20 /var/log/frpc.log
# Good: "login to server success", "proxy added: [s0_rtsp s1_rtsp s2_rtsp]"
# Bad: "dial tcp ... i/o timeout" (wrong IP), "authorization failed" (wrong token)
```

## Quick Workflow

### Start Everything
```bash
./build.sh         # Rebuild if live_stream.c changed
infra/system start     # Start frpc + all DeepStream containers
```

### Stop Everything
```bash
infra/system stop      # Stop all containers + frpc
```

### Check Status
```bash
infra/system status        # Full health check (frpc, DS, relay) - USE THIS FIRST
./ds status            # Just container status
infra/relay status         # Just relay status
infra/scripts/debug.sh    # Detailed diagnostics
```

### Debug Issues
```bash
infra/scripts/debug.sh    # ALWAYS run this first for debugging
# Only check individual logs if debug script tells you to
```

### View processed streams
- s0: `http://34.47.221.242:8889/s0/`
- s1: `http://34.47.221.242:8889/s1/`
- s2: `http://34.47.221.242:8889/s2/`
- s3: `http://34.47.221.242:8889/s3/`

### View input streams (before processing)
- in_s0: `http://34.47.221.242:8889/in_s0/`
- in_s1: `http://34.47.221.242:8889/in_s1/`
- in_s2: `http://34.47.221.242:8889/in_s2/`
- in_s3: `http://34.47.221.242:8889/in_s3/`

## Swapping Models

To change from YOLOv8n to another model:
```bash
# 1. Create new config pointing to new ONNX
cp config/config_infer_yolov8.txt config/config_infer_new.txt
vim config/config_infer_new.txt
# Update: onnx-file=/models/new_model.onnx
# Update: model-engine-file=/models/new_model_b1_gpu0_fp16.engine

# 2. Edit inference config path in live_stream.c
sed -i 's|config_infer_yolov8.txt|config_infer_new.txt|' live_stream.c

# 3. Rebuild and restart
./build.sh
./ds restart

# DeepStream will auto-build the new engine (no need to delete old ones)
```

## TensorRT Engine Management

### How Engine Caching Actually Works (CRITICAL UNDERSTANDING)

**DeepStream saves engines to `/app/`, NOT `/models/`**:
- Config specifies: `model-engine-file=/models/xxx.engine` (where it LOADS from)
- DeepStream saves to: `/app/model_b1_gpu0_fp16.engine` (hardcoded in DeepStream-YOLO)
- `/app/` is NOT bind-mounted ‚Üí engines lost on container restart
- `/models/` IS bind-mounted ‚Üí engines persist across restarts

**The Problem**: First run builds engine to `/app/`, second run can't find it in `/models/`, rebuilds again.

**The Solution**: Use `infra/scripts/cache_engine.sh` to copy engines from `/app/` ‚Üí `/models/` with correct names.

### Engine Cache Management Script

Use `infra/scripts/cache_engine.sh` for all engine operations:

```bash
# After first container start (engines built in /app/)
infra/scripts/cache_engine.sh copy     # Copy engines to /models/ with correct names

# Check engine locations
infra/scripts/cache_engine.sh list     # Show engines in containers + /models/

# Verify configs point to existing cached engines
infra/scripts/cache_engine.sh verify   # Check config ‚Üí engine mappings

# Force clean rebuild (rarely needed)
infra/scripts/cache_engine.sh clean    # Delete cached engines from /models/
./ds restart                        # Containers rebuild in /app/
infra/scripts/cache_engine.sh copy     # Copy to /models/ again
```

### Typical Workflow: Adding New Model

```bash
# 1. Train and export ONNX (in training/)
cp training/path/to/best.onnx models/new_model.onnx

# 2. Create/update config
vim config/config_infer_new.txt
# onnx-file=/models/new_model.onnx
# model-engine-file=/models/new_model_b1_gpu0_fp16.engine

# 3. Update container config in ds script or live_stream.c
# 4. Start containers (engines build in /app/)
./ds restart

# 5. Wait for "Pipeline set to PLAYING" (3-10 min depending on model)
docker logs ds-s2 | grep "PLAYING"

# 6. Copy engines to cache
infra/scripts/cache_engine.sh copy

# 7. Verify configs point to cached engines
infra/scripts/cache_engine.sh verify

# 8. Restart to verify cache reuse (should be instant)
./ds restart
docker logs ds-s2 | grep "deserialized trt engine"
# Should see: "deserialized trt engine from :/models/new_model_b1_gpu0_fp16.engine"
```

### How Caching Works After Setup

```
First Run (no cache):
1. DeepStream checks /models/xxx.engine ‚Üí not found
2. Builds engine from ONNX (3-10 minutes)
3. Saves to /app/model_b1_gpu0_fp16.engine
4. Runs inference

Manual step:
5. infra/scripts/cache_engine.sh copy ‚Üí copies /app/ ‚Üí /models/ with correct name

Second Run (with cache):
1. DeepStream checks /models/xxx.engine ‚Üí found!
2. Deserializes from cache (instant)
3. Runs inference

Without manual copy, step 1 fails every restart ‚Üí rebuild loop
```

### When to Use cache_engine.sh

**ALWAYS run after**:
1. First deployment of new model
2. Rebuilding engines (after ONNX change)
3. Moving to different GPU architecture

**Check cache status**:
```bash
infra/scripts/cache_engine.sh list
```

**Expected output after successful cache**:
```
=== Engines in /models/ (bind-mounted, persistent) ===
-rw-r--r-- 1 root root 56M Oct 23 14:03 bowling_roboflow_1280_b1_gpu0_fp16.engine
-rw-r--r-- 1 root root 11M Oct 23 14:05 yolov8n_b1_gpu0_fp16.engine
```

### Only Delete Engines If
1. **Testing fresh build** - want to time build process
2. **Debugging engine corruption** - engine crashes on deserialize
3. **Disk cleanup** - removing old unused engines

```bash
# Delete specific engine
infra/scripts/cache_engine.sh clean    # Or manually:
rm /root/d_final/models/old_model_b1_gpu0_fp16.engine
```

## Performance

All 4 streams process at ~30 FPS with YOLOv8n in portrait mode (720x1280). Check with:
```bash
infra/scripts/debug.sh    # Shows GPU usage and container status
```

GPU memory usage per container: ~390 MiB

## Recent Changes

### Major Cleanup (2025-10-20)
1. **DRY principle**: Replaced 3 duplicate C files with single parameterized `live_stream.c`
2. **Script consolidation**: Simplified 11 scripts down to 4 (`system`, `ds`, `relay`, `build.sh`)
3. **Utilities hidden**: Moved check.sh, debug.sh, frpc config to `infra/scripts/`
4. **Publisher removed**: All publisher code removed from codebase (use external publisher for testing)

### Benefits
- **Simpler IP updates**: 2 files instead of 6
- **Easier management**: `infra/system start` for everything, `./ds start` for containers only
- **Clean separation**: Core system only, test tools external

### Component Separation
- **Production system**: `/root/d_final/` - frpc + DeepStream (s0, s1, s2, s3) - managed by `infra/system`
- **Training system**: `/root/d_final/training/` - model training and ONNX export
- **Relay**: Remote infrastructure - managed by `infra/relay`

### Migration Notes
If you have old code referencing:
- `live_s0/s1/s2` binaries ‚Üí Use `/app/live_stream 0/1/2` instead
- `start.sh/stop.sh` ‚Üí Use `infra/system start/stop` or `./ds start/stop`
- `frpc/frpc.ini` ‚Üí Now `infra/scripts/frpc/frpc.ini`
- `check.sh/debug.sh` ‚Üí Now `infra/scripts/check.sh` and `infra/scripts/debug.sh`

## Expectations for AI Agents

1. **ALWAYS use managed scripts**: `infra/system`, `./ds`, `infra/relay`, `infra/scripts/debug.sh` - NOT raw docker/frp/mediamtx commands
2. **Check status before debugging**: Run `infra/system status` and `infra/scripts/debug.sh` before investigating issues
3. **Relay is immutable**: Changes to `relay_infra/scripts/startup.sh` require terraform destroy/apply
4. **frpc is critical**: Without it, relay can't pull processed streams - manage via `infra/system`
5. **All 4 streams identical**: Same binary, same config, just different stream ID (0-3) and orientation
6. **Don't modify working streams**: If s0-s2 work but s3 doesn't, leave s0-s2 alone
7. **NEVER delete TensorRT engines**: Engines are cached in `/models/` (bind-mounted from host) and persist across restarts - DeepStream auto-rebuilds when needed
8. **Training separation**: Production code in `/root/d_final/`, training experiments in `/root/d_final/training/`

## Training Workflow

### Separation of Concerns
- **Production**: `/root/d_final/` - deployed code, managed via `infra/system`, `./ds`, `infra/relay`
- **Training**: `/root/d_final/training/` - model training, ONNX export, experiments
- **Models**: `/root/d_final/models/` - production ONNX files only

### Training Directory Structure
```
training/
‚îú‚îÄ‚îÄ train_bowling.py              # Training script
‚îú‚îÄ‚îÄ Bowling-Pin-Detection--4/     # Roboflow dataset (868 images, 1 class)
‚îÇ   ‚îú‚îÄ‚îÄ train/images/
‚îÇ   ‚îú‚îÄ‚îÄ valid/images/
‚îÇ   ‚îî‚îÄ‚îÄ data.yaml
‚îî‚îÄ‚îÄ roboflow_bowling/             # Training runs
    ‚îú‚îÄ‚îÄ bowling_1280_m_b8/        # YOLOv8m, batch=8, 1280x1280
    ‚îÇ   ‚îî‚îÄ‚îÄ weights/
    ‚îÇ       ‚îú‚îÄ‚îÄ best.pt           # 92.7% precision, 88.9% recall
    ‚îÇ       ‚îî‚îÄ‚îÄ best.onnx         # Exported ONNX
    ‚îî‚îÄ‚îÄ ...other experiments
```

### Adding New Models
```bash
# 1. Train in /root/d_final/training/
cd /root/d_final/training
python3 train_bowling.py --imgsz 1280 --batch 8 --epochs 150

# 2. Export ONNX with FIXED dimensions (dynamic=False)
docker run --rm --gpus all -v /root/d_final/training:/data \
  ultralytics/ultralytics:latest yolo export \
  model=/data/roboflow_bowling/bowling_1280_m_b8/weights/best.pt \
  format=onnx imgsz=1280 dynamic=False simplify=True

# 3. Copy to production models/
cp training/roboflow_bowling/bowling_1280_m_b8/weights/best.onnx \
   models/bowling_roboflow_1280.onnx

# 4. Create or update config
cp config/config_infer_yolov8.txt config/config_infer_bowling.txt
vim config/config_infer_bowling.txt
# Update: onnx-file=/models/bowling_roboflow_1280.onnx
# Update: model-engine-file=/models/bowling_roboflow_1280_b1_gpu0_fp16.engine
# Update: num-detected-classes=1
# Update: labelfile-path=/models/bowling_labels.txt

# 5. Restart container - engine builds automatically
./ds restart

# NO need to delete engines - DeepStream auto-rebuilds when missing
```

### Current Models
- **s0, s1**: YOLOv8n COCO (80 classes) - 720x1280 portrait
- **s2**: YOLOv8n COCO (80 classes) - 720x1280 portrait
- **s3**: YOLOv8m Bowling Roboflow (1 class) - 720x1280 portrait, 92.7% precision

### Training Lessons Learned
- **Use dynamic=False**: DeepStream requires fixed input dimensions, not variable
- **Batch size matters**: batch=8 works with concurrent DeepStream; batch=16 needs more GPU memory
- **Early stopping works**: YOLOv8m reached 92.7% precision at epoch 70 with patience=20
- **Roboflow datasets**: Company datasets often better than auto-labeled custom data
- **Export format**: Use DeepStream-Yolo export scripts with Ultralytics base image for proper output layer format
  - Script: `training/scripts/export_deepstream.sh`
  - Uses DeepStream-Yolo's export_yoloV8.py with DeepStreamOutput layer
  - Ensures compatibility with custom parser (libnvdsinfer_custom_impl_Yolo.so)

## EdgeTAM Segmentation Model

### Overview

EdgeTAM is an on-device variant of SAM 2 (Segment Anything Model 2) optimized for real-time video segmentation and tracking.

**Key Features**:
- **Speed**: 22x faster than SAM 2, achieves 16 FPS on iPhone 15 Pro Max
- **Size**: 13.9M parameters (compact for edge deployment)
- **Capabilities**: Image and video object segmentation, multi-object tracking
- **Inputs**: Points, bounding boxes, previous masks
- **Outputs**: Binary segmentation masks, IoU predictions

### Architecture for DeepStream

EdgeTAM uses a **two-stage architecture** for ONNX export:

**Stage 1: Image Encoder**
- Input: RGB image (1√ó3√ó1024√ó1024)
- Outputs:
  - `image_embeddings`: 1√ó256√ó64√ó64
  - `high_res_features_0`: 1√ó32√ó256√ó256
  - `high_res_features_1`: 1√ó64√ó128√ó128
- Role: Extract visual features once per frame

**Stage 2: Mask Decoder**
- Inputs:
  - `image_embeddings` from encoder
  - `input_points`: Point prompts (Nx2, coordinates)
  - `input_labels`: Point labels (N, 1=foreground, 0=background)
  - `original_sizes`: Image dimensions for coordinate scaling
- Outputs:
  - `masks`: Binary segmentation masks (H√óW)
  - `iou_predictions`: Quality scores for each mask
  - `low_res_masks`: Low-res logits for mask refinement
- Role: Generate masks for prompted objects

### DeepStream Integration Strategy

**Pipeline Architecture**:
```
nvurisrcbin ‚Üí nvstreammux ‚Üí
  nvinfer (encoder) ‚Üí
  nvinfer (decoder) ‚Üí
  nvdsosd (draw masks) ‚Üí
  encoder ‚Üí rtspout
```

**Key Challenges**:
1. **Two-stage inference**: Encoder outputs must be passed to decoder as inputs
   - Solution: Use `output-tensor-meta=1` in encoder config, custom plugin to bridge
2. **Prompt generation**: Decoder requires point prompts for mask generation
   - Solution: Use automatic mask generation mode (grid of points) or YOLO detections as prompts
3. **Mask visualization**: DeepStream `nvdsosd` doesn't natively support instance segmentation
   - Solution: Custom CUDA kernel or use `nvdspostprocess` for mask overlay

### Export Script

Location: `training/scripts/export_edgetam.py`

```bash
# Export EdgeTAM encoder and decoder to ONNX
python3 training/scripts/export_edgetam.py \
  --model_id yonigozlan/EdgeTAM-hf \
  --output_dir /root/d_final/models \
  --image_size 1024
```

Generates:
- `models/edgetam_encoder.onnx` - Image encoder
- `models/edgetam_decoder.onnx` - Mask decoder

### TensorRT Conversion

```bash
# Convert encoder
trtexec --onnx=/root/d_final/models/edgetam_encoder.onnx \
  --saveEngine=/root/d_final/models/edgetam_encoder.engine \
  --fp16 --batch=1

# Convert decoder
trtexec --onnx=/root/d_final/models/edgetam_decoder.onnx \
  --saveEngine=/root/d_final/models/edgetam_decoder.engine \
  --fp16 --batch=1
```

### Configuration Files

**Encoder Config** (`config/s3_edgetam_encoder.txt`):
```ini
[property]
gpu-id=0
onnx-file=/models/edgetam_encoder.onnx
model-engine-file=/models/edgetam_encoder.engine
network-type=100          # Custom output (raw tensors)
output-tensor-meta=1      # Attach tensor metadata
batch-size=1
network-mode=2            # FP16
```

**Decoder Config** (`config/s3_edgetam_decoder.txt`):
```ini
[property]
gpu-id=0
onnx-file=/models/edgetam_decoder.onnx
model-engine-file=/models/edgetam_decoder.engine
network-type=100          # Custom segmentation
output-tensor-meta=1
batch-size=1
network-mode=2            # FP16
parse-bbox-instance-mask-func-name=NvDsInferParseCustomEdgeTAM
custom-lib-path=/app/libnvdsinfer_custom_impl_EdgeTAM.so
```

### Custom Parser Implementation

Location: `nvdsinfer_custom_impl_EdgeTAM/` (to be created)

Must implement:
- `NvDsInferParseCustomEdgeTAM()`: Parse mask decoder outputs
- Extract masks, IoU scores from output tensors
- Attach `NvDsInferSegmentationMeta` to frame metadata
- Convert masks to displayable format for `nvdsosd`

### C Application

**Binary**: `live_stream_edgetam`
**Config**: Takes stream ID (0-3) and runs EdgeTAM segmentation

```bash
# Run EdgeTAM on stream 3
docker run -d --name ds-s3 --gpus all --net=host \
  -v /root/d_final/config:/config \
  -v /root/d_final/models:/models \
  ds-s1:latest /app/live_stream_edgetam 3 portrait
```

### Workflow: Adding EdgeTAM to Stream

```bash
# 1. Export EdgeTAM to ONNX
python3 training/scripts/export_edgetam.py --output_dir models/

# 2. Convert to TensorRT (or let DeepStream auto-build)
# DeepStream will auto-build on first run if ONNX exists

# 3. Create custom parser library
cd nvdsinfer_custom_impl_EdgeTAM/
make
# Builds libnvdsinfer_custom_impl_EdgeTAM.so

# 4. Update build.sh to include EdgeTAM parser
vim build.sh
# Add EdgeTAM parser compilation step

# 5. Build and deploy
./build.sh
./ds_simple start  # Runs EdgeTAM on ds-s3

# 6. Verify segmentation output
# View at http://34.47.221.242:8889/s3/
```

### Performance Expectations

- **FPS**: 10-20 FPS on RTX 5080 (two-stage inference overhead)
- **GPU Memory**: ~1-2 GiB (encoder + decoder + frame buffers)
- **Latency**: 50-100ms per frame (depends on number of prompts)

**Note**: EdgeTAM is optimized for mobile devices (INT8 quantization on ARM). On desktop GPU with FP16, expect similar or better performance than mobile baseline (16 FPS).

### Current Status

- [x] Export script created (`training/scripts/export_edgetam.py`)
- [ ] ONNX models exported
- [ ] TensorRT engines built
- [ ] Custom parser implemented
- [ ] Config files created
- [ ] `live_stream_edgetam.c` implemented
- [ ] Tested on ds-s3

### References

- **Model**: https://huggingface.co/yonigozlan/EdgeTAM-hf
- **Paper**: EdgeTAM: On-Device Track Anything Model (CVPR 2025)
- **License**: Apache 2.0
